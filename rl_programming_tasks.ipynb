{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26.2\n"
     ]
    }
   ],
   "source": [
    "from plt_utils import *\n",
    "from test_levels import *\n",
    "import gym\n",
    "\n",
    "print(gym.__version__)\n",
    "# env = time_level()\n",
    "env = trivial()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Given env.P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## policy computation\n",
    "- policy_update corresponds to $f_v$ <br>\n",
    "- value_update(iterations =1) corresponds to $L_{\\text{policy}}$ <br>\n",
    "- value_update_seidel(iterations =1) uses updated values of v \n",
    "as soon that they are updated like gauss-seidel method. <br>\n",
    "\n",
    "- value_iteration is applying $L_{f_v}v = Uv$ (theorem 1.3.5)  <br>\n",
    "- backward_induction is value_iteration with $v^{T+1} =0$ and time dependence (theorem 1.2.1) <br>\n",
    "- policy_iteration is generalized_iteration because of (theorem 1.3.6) <br>\n",
    "we don't apply $L_{\\pi}$ infinite times but to convergence or $1000$ \n",
    "iterations.\n",
    "\n",
    "the code is obvious, there is a small difference in the formula <br> \n",
    "because rewards are defined differently so you take it in the sum <br>\n",
    "that way you get averaged reward corresponding to our definition <br>\n",
    "and you can decode $b$ with: <br>\n",
    "env.P[state][action] = [(probability, nextstate, reward, done), ...] <br>\n",
    "(To make backward induction time dependent just make env.P[state][action] \n",
    "time dependent.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def states(env): return range(env.observation_space.n)\n",
    "def actions(env, state): return env.P[state].keys()\n",
    "# infmetric, norm, only works for v\n",
    "def oometric(v1, v2): return max(abs(v1[i]-v2[i]) for i in v1.keys())\n",
    "\n",
    "def value_update(env, alpha, v, policy, iterations=1, eps=10**(-4)):\n",
    "    for _ in range(iterations): \n",
    "        vold = v.copy() \n",
    "        for state in states(env): \n",
    "            v[state] = sum(b[0]*(b[2]+alpha*vold[b[1]]) \n",
    "                           if not(b[3]) else b[0]*b[2] for b in env.P[state][policy[state]])\n",
    "        if oometric(v, vold) < eps: break #convergence\n",
    "\n",
    "def value_update_seidel(env, alpha, v, policy, iterations=1, eps=10**(-4)):\n",
    "    for _ in range(iterations): \n",
    "        vold = v.copy() \n",
    "        for state in states(env): \n",
    "            v[state] = sum(b[0]*(b[2]+alpha*v[b[1]]) # v instead vold, an OG error  for finite problem\n",
    "                           if not(b[3]) else b[0]*b[2] for b in env.P[state][policy[state]])\n",
    "        if oometric(v, vold) < eps: break #convergence\n",
    "\n",
    "\n",
    "def policy_update(env, alpha, v, policy):\n",
    "    for state in states(env):\n",
    "        max_a, max_val = 0, -float(\"inf\") #to select the argmax\n",
    "        for action in actions(env, state):\n",
    "            val = sum(b[0]*(b[2]+alpha*v[b[1]]) if not(b[3]) else b[0]*b[2] for b in env.P[state][action])\n",
    "            max_a, max_val = (action, val) if val > max_val else (max_a, max_val)\n",
    "        policy[state] = max_a\n",
    "\n",
    "def value_iteration(env,alpha,max_iter = 30,eps = 10**(-6)):\n",
    "    v = {state:0 for state in states(env)} \n",
    "    policy = {state:0 for state in states(env)} \n",
    "    vv,pp = [],[] #these are for plotting\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        policy_update(env,alpha,v,policy)\n",
    "        value_update(env,alpha,v,policy,iterations=1)\n",
    "        vv.append(v.copy()) # history of value functions\n",
    "        pp.append(policy.copy()) # policy history\n",
    "        if i>2 and oometric(vv[-1], vv[-2]) < eps: break\n",
    "    return vv,pp\n",
    "\n",
    "def backward_induction(env,alpha,T):\n",
    "    return value_iteration(env,alpha,T,0)\n",
    "\n",
    "def generalized_iteration(env,alpha,inner_iter=1,max_iter = 30,eps = 10**(-6)):\n",
    "    v = {state:0 for state in states(env)} \n",
    "    policy = {state:0 for state in states(env)} \n",
    "    vv,pp = [],[] #these are for plotting\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        value_update(env,alpha,v,policy,inner_iter,eps)\n",
    "        policy_update(env,alpha,v,policy)\n",
    "        vv.append(v.copy()) # history of value functions\n",
    "        pp.append(policy.copy()) # policy history\n",
    "        if i>2 and pp[-1]==pp[-2]==pp[-3]: break\n",
    "    return vv,pp\n",
    "\n",
    "def policy_iteration(env,alpha,max_iter = 30,eps = 10**(-6)):\n",
    "    return generalized_iteration(env=env,alpha=alpha,inner_iter=10**3,max_iter = max_iter,eps = eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 2), (2, 3), (3, 3), (4, 2), (5, 2), (6, 2), (7, 2), (8, 1), (9, 0), (10, 0), (11, 0), (12, 2), (13, 1), (14, 1), (15, 1), (16, 1), (17, 0), (18, 0), (19, 1), (20, 2), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 2), (35, 2), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 2), (42, 2), (43, 2), (44, 2), (45, 1), (46, 1), (47, 1), (48, 1), (49, 2), (50, 2), (51, 2), (52, 2), (53, 2), (54, 1), (55, 1), (56, 1), (57, 2), (58, 2), (59, 2), (60, 2), (61, 2), (62, 2), (63, 0)]\n",
      "val(0) = 0.955359377777257 at time 1 for finite horizon\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6732f93fe124eb59396a3a265f8998c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='iterations', max=17), IntSlider(value=0, description='roâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# bvv,bpp = backward_induction(env,alpha=1,T=1000) #programming task 1\n",
    "vv,pp = policy_iteration(env,alpha=0.999,max_iter=50,eps=10**(-6)) #programming task 2\n",
    "# vv,pp = value_iteration(env,alpha=0.999,max_iter=300,eps = 0.001) #programming task 3\n",
    "sol = list(pp[-1].items()) # asked form of the policy\n",
    "print(sol)\n",
    "print(f\"val(0) = {vv[-1][0]} at time 1 for finite horizon\")\n",
    "intvp(vv,pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## policy evaluation\n",
    "value_eval is for evaluating a policy, basically it is a big  <br>\n",
    "average of the rewards times the probability of getting it <br>\n",
    "lot of terms can be reused, value_update does it basically "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finite_value_eval(env,alpha,pp):\n",
    "    v = {state:0 for state in states(env)} \n",
    "    vv= []\n",
    "    for p in pp:\n",
    "        value_update(env,alpha,v,p,1,0)\n",
    "        vv.append(v.copy())\n",
    "    print(f\"val(0) = {vv[-1][0]} at time 1 for finite horizon\")\n",
    "    return vv\n",
    "\n",
    "def infinite_value_eval(env,alpha,policy,eps=10**(-6)):\n",
    "    v = {state:0 for state in states(env)} \n",
    "    value_update(env,alpha,v,policy,10**5,eps)\n",
    "    print(f\"val(0) = {v[0]} for infinite horizon\")\n",
    "    return v \n",
    "\n",
    "def random_policy(env,T):\n",
    "    return [{state:env.action_space.sample() \n",
    "            for state in states(env)}\n",
    "            for _ in range(T)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val(0) = 0.9553523997340856 for infinite horizon\n",
      "reference = 0.955359377777257\n"
     ]
    }
   ],
   "source": [
    "pvv,ppp = policy_iteration(env,alpha=0.999,max_iter=50,eps=10**(-6)) \n",
    "pv = infinite_value_eval(env,0.999,ppp[-1])\n",
    "print(f\"reference = {pvv[-1][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val(0) = 0.010874736571158946 at time 1 for finite horizon\n",
      "reference = 0.010874736571158946\n"
     ]
    }
   ],
   "source": [
    "bvv,bpp = backward_induction(env,alpha=1,T=30) \n",
    "bbvv = finite_value_eval(env,1,bpp)\n",
    "print(f\"reference = {bvv[-1][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val(0) = 0.057083790103964104 at time 1 for finite horizon\n"
     ]
    }
   ],
   "source": [
    "rpp = random_policy(env,2000)\n",
    "rvv = finite_value_eval(env,1,rpp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation based\n",
    "## MC evaluation\n",
    "Evaluation is easy with MC estimation but it is really slow ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MC_eval(env,pol,alpha,T=10**3,nsim = 10**3):\n",
    "    # does MC estimation of the expected reward\n",
    "    running_sum = 0\n",
    "    for _ in range(nsim):\n",
    "        stat = env.reset()\n",
    "        # state = env.reset() #google colab\n",
    "        total_reward = 0\n",
    "        state = stat[0]\n",
    "        for t in range(T): \n",
    "            action = pol[t][state]\n",
    "            state, reward, done, _, _ = env.step(action)\n",
    "            total_reward += alpha**t*reward\n",
    "            if done: break\n",
    "        env.close()\n",
    "        running_sum +=total_reward/nsim\n",
    "    return running_sum\n",
    "\n",
    "def infinite_pol_rep(p,T):\n",
    "    return {t: {i:p[i] \n",
    "              for i in range(env.observation_space.n)}\n",
    "                for t in range(T)}\n",
    "\n",
    "def finite_pol_rep(pp,T):\n",
    "    return {t: {i:pp[-t-1][i] \n",
    "              for i in range(env.observation_space.n)}\n",
    "                for t in range(T)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC eval = 0.9554627777139812\n",
      "reference = 0.955359377777257\n"
     ]
    }
   ],
   "source": [
    "pvv,ppp = policy_iteration(env,alpha=0.999,max_iter=50,eps=10**(-6)) \n",
    "T = 10**3 # basically infinity\n",
    "rep_ppp = infinite_pol_rep(ppp[-1],T)\n",
    "pMC = MC_eval(env,rep_ppp,0.999,T,10**3)\n",
    "print(f\"MC eval = {pMC}\")\n",
    "print(f\"reference = {pvv[-1][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC eval = 0.07600000000000005\n",
      "reference = 0.07595414188519159\n"
     ]
    }
   ],
   "source": [
    "bvv,bpp = backward_induction(env,alpha=1,T=50) \n",
    "T = len(bpp)\n",
    "rep_bpp = infinite_pol_rep(bpp[-1],T)\n",
    "bMC = MC_eval(env,rep_bpp,1,T,10**3)\n",
    "print(f\"MC eval = {bMC}\")\n",
    "print(f\"reference = {bvv[-1][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume we know the states and the actions ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val(0) = 0.0 for infinite horizon\n",
      "val(0) = 0.0 for infinite horizon\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_action_from_q(q,state):\n",
    "    max_a , max_val = 0, q[state][0]\n",
    "    for action,val in q[state].items():\n",
    "        max_a, max_val = (action, val) if val > max_val else (max_a, max_val)\n",
    "    return max_a,max_val    \n",
    "\n",
    "def get_q_from_v(env,v):\n",
    "    q = {state:{action:0 for action in actions(env,state) } for state in states(env)}\n",
    "    for state in states(env):\n",
    "        for action in actions(env,state): \n",
    "            val = sum(b[0]*(b[2]+v[b[1]]) for b in env.P[state][action]) # uses P\n",
    "            q[state][action]= val\n",
    "    return q\n",
    "\n",
    "def get_policy_from_q(env,q):\n",
    "    return {state:get_action_from_q(q,state)[0] for state in states(env)}\n",
    "\n",
    "def Q_learning(env,v,alpha,gamma,T=10**3,nsim = 10**3):\n",
    "    q = get_q_from_v(env,v)\n",
    "    for i in range(nsim):\n",
    "        stat = env.reset()\n",
    "        # state = env.reset() #google colab\n",
    "        state = stat[0]\n",
    "        for t in range(T): \n",
    "            action, qval = get_action_from_q(q,state)\n",
    "            state, reward, done, _, _ = env.step(action)\n",
    "            q[state][action] = (1-gamma)*(q[state][action])+ gamma*(reward+alpha*qval)\n",
    "            if done: break\n",
    "        env.close()\n",
    "    return q \n",
    "\n",
    "\n",
    "bv = infinite_value_eval(env,1,bpp[10])\n",
    "\n",
    "q= Q_learning(env,bv,1,1,T=10**3,nsim=10**2)\n",
    "qv = infinite_value_eval(env,1,get_policy_from_q(env,q))\n",
    "dv = {state:(qv[state]-bv[state]) for state in states(env)}\n",
    "visv(dv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
